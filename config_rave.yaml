seed_everything: 42
model:
  class_path: rave.model.RAVE
  init_args:
    data_size: 16
    capacity: 32 # 32 for small
    latent_size: 128
    ratios: [4, 4, 4, 2] # small: [4, 4, 4, 2], large: [4, 4, 2, 2, 2]
    bias: true
    loud_stride: 1
    use_noise: true
    noise_ratios: [4, 4, 4]
    noise_bands: 5
    d_capacity: 16
    d_multiplier: 4
    d_n_layers: 4
    warmup: 1000000  # large=3000000
    mode: "hinge"
    no_latency: false
    sr: 44100
    min_kl: 0.1
    max_kl: 0.3
    cropped_latent_size: 0
    feature_match: true

# ------------------ Datasets ------------------       
# data:
#   class_path: data.data.RAVEDataModule
#   init_args:
#     data_dir: "out_44100" 
#     batch_size: 8
#     batch_size_val: 8
#     num_workers: 8
#     sr: 44100
#     n_signal: 65536
#     preprocessed: ".tmp"


data:
  class_path: data.data.DataModule
  init_args:
    dataset_dirs: 
      - "/home/cyran/RAVE/"

# ------------------ Data loading hyperparameters ------------------       
    batch_size: 16
    batch_size_val:  16
    nr_samples: 65536
    normalize: true
    num_workers: 40
    positive_examples: "same_clip" # or same_group
    batch_sampling_mode: "sample_clips" # or sample groups
    eval_frac: 0.02
    mask_samples: false
    verbose: true
    use_random_loader: false
    group_name_is_folder: true
    group_by_artist: false


# ------------------ Training ------------------
trainer:
  gpus: 1 # check
  max_epochs: 100000
  max_steps: 3000000
  val_check_interval: 2000
  # check_val_every_n_epoch: 
  # ckpt: None

# ------------------ Logger ------------------
  logger:
    class_path: pytorch_lightning.loggers.TensorBoardLogger
    init_args:
      save_dir: "runs/test_config"
      name: "rave"

# ------------------ Checkpoint callbacks ------------------
  callbacks:
    - class_path: pytorch_lightning.callbacks.ModelCheckpoint
      init_args:
        #dirpath: ""
        monitor: "validation"
        mode: "min"
        filename: "best-{epoch}-{step}"
    # - class_path: pytorch_lightning.callbacks.ModelCheckpoint
    #   init_args:
    #     every_n_epochs: 20
    #     filename: "best-{epoch}-{step}"
    - class_path: pytorch_lightning.callbacks.ModelCheckpoint
      init_args:
        filename: "last"